{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip install datasets\n!pip install sentencepiece\n!pip install datasets\n!pip install transformers\n!pip install torch\nfrom datasets import load_dataset\nimport pandas as pd\nimport csv\nfrom datasets import load_dataset\nimport torch as th\nfrom transformers import T5Tokenizer, T5Model,T5ForConditionalGeneration,T5Config\nfrom transformers import get_scheduler\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW\nimport torch\n\ntrain_dataset = load_dataset(\"jfleg\", split='validation[:]')\n\neval_dataset = load_dataset(\"jfleg\", split='test[:]')\ndef generate_csv(csv_path, dataset):\n    with open(csv_path, 'w', newline='') as csvfile:\n        writter = csv.writer(csvfile)\n        writter.writerow([\"input\", \"target\"])\n        for case in dataset:\n     \t    # Adding the task's prefix to input \n            input_text = \"grammar: \" + case[\"sentence\"]\n            for correction in case[\"corrections\"]:\n                # a few of the cases contain blank strings. \n                if input_text and correction:\n                    writter.writerow([input_text, correction])\n                    \n\n\ngenerate_csv(\"train.csv\", train_dataset)\ngenerate_csv(\"eval.csv\", eval_dataset)\ntrain_dataset=pd.read_csv('./train.csv')\neval_dataset=pd.read_csv('./eval.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T07:39:03.649536Z","iopub.execute_input":"2022-05-05T07:39:03.650250Z","iopub.status.idle":"2022-05-05T07:39:50.252537Z","shell.execute_reply.started":"2022-05-05T07:39:03.650203Z","shell.execute_reply":"2022-05-05T07:39:50.251728Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:30px;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n               Text Preprocessing\n\n</div>","metadata":{}},{"cell_type":"code","source":"\nreplacements = [\n  (\" .\", \".\"), \n  (\" ,\", \",\"),\n  (\" '\", \"'\"),\n  (\" ?\", \"?\"),\n  (\" !\", \"!\"),\n  (\" :\", \"!\"),\n  (\" ;\", \"!\"),\n  (\" n't\", \"n't\"),\n  (\" v\", \"n't\"),\n  (\"2 0 0 6\", \"2006\"),\n  (\"5 5\", \"55\"),\n  (\"4 0 0\", \"400\"),\n  (\"1 7-5 0\", \"1750\"),\n  (\"2 0 %\", \"20%\"),\n  (\"5 0\", \"50\"),\n  (\"1 2\", \"12\"),\n  (\"1 0\", \"10\"),\n  ('\" ballast water', '\"ballast water')\n]\n\ndef remove_excess_spaces(text):\n  for rep in replacements:\n    text = text.replace(rep[0], rep[1])\n\n  return text\nsentence=pd.Series(train_dataset['input']).map(lambda x : remove_excess_spaces(x))\ncorrection=pd.Series(train_dataset['target']).map(lambda xx : remove_excess_spaces(xx) )\ntask_prefix = \"grammar: \"\n\ntrain=pd.DataFrame(columns=['sent','corr'])\n\nfor i in range(len(sentence)):\n        train=train.append({'sent': sentence[i],'corr':correction[i]}, ignore_index=True)\n            \n    \nqns = list(train[\"sent\"])\nprint(len(qns)) \n\n\nclass GSMDataset(th.utils.data.Dataset):\n    def __init__(self, tokenizer,dataset, loss_on_prefix=True):\n        self.examples = dataset\n        self.qns = list(self.examples[\"sent\"])\n        self.ans = list(self.examples[\"corr\"])\n        self.qns = tokenizer(self.qns,padding='max_length', max_length=418, truncation=True, return_tensors=\"pt\")\n        self.ans = tokenizer(self.ans,padding='max_length',max_length=405, truncation=True)\n        \n        self.loss_on_prefix = loss_on_prefix\n\n    def __len__(self):\n        return len(self.examples)\n\n    def __getitem__(self, idx):\n        qn_tokens = self.qns[\"input_ids\"][idx]\n        qn_att=self.qns[\"attention_mask\"][idx]\n        ans_tokens = self.ans[\"input_ids\"][idx]\n        ans_tokens = [-100 if x==0 else x for x in ans_tokens] \n        qn_tokens = th.tensor(qn_tokens)\n        qn_att = th.tensor(qn_att)\n        ans_tokens=th.tensor(ans_tokens)\n        \n        return dict(input_ids= qn_tokens, attention_mask=qn_att,labels=ans_tokens)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:39:50.254276Z","iopub.execute_input":"2022-05-05T07:39:50.254527Z","iopub.status.idle":"2022-05-05T07:39:55.248501Z","shell.execute_reply.started":"2022-05-05T07:39:50.254491Z","shell.execute_reply":"2022-05-05T07:39:55.247726Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:30px;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n               Tokenization and parameter initilization\n\n</div>","metadata":{}},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\nconfig = T5Config.from_pretrained(\"t5-small\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"t5-small\",config=config,)\ntrain_set= GSMDataset(tokenizer,train)\nmodel.train()\ntrain_loader = DataLoader(train_set, batch_size=8, shuffle=True)\noptim = AdamW(model.parameters(), lr=1e-5)\n\nnum_epochs = 10\nnum_training_steps = num_epochs * len(train_loader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optim,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\n\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:39:55.249633Z","iopub.execute_input":"2022-05-05T07:39:55.250046Z","iopub.status.idle":"2022-05-05T07:41:01.668661Z","shell.execute_reply.started":"2022-05-05T07:39:55.250007Z","shell.execute_reply":"2022-05-05T07:41:01.667305Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:30px;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n               Model Training \n\n</div>","metadata":{}},{"cell_type":"code","source":"pbar = tqdm(range(num_training_steps))\nfor epoch in range(num_epochs):\n        for batch in train_loader:\n            optim.zero_grad()\n            b_input_ids,b_attention_mask,b_labels= batch.items()\n            outputs = model(input_ids=batch[\"input_ids\"],attention_mask=batch[\"attention_mask\"], labels=torch.tensor(batch[\"labels\"]))\n            loss = outputs[0]\n            loss.backward()\n            optim.step()\n            lr_scheduler.step()\n            pbar.update(1)\n            pbar.set_description(f\"train_loss: {loss.item():.5f}\")\n            model.save_pretrained(\"model_ckpts/\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:30px;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n               Prediction phase\n</div>","metadata":{}},{"cell_type":"code","source":"model_path = \"/content/model_ckpts\"\nmodel = T5ForConditionalGeneration.from_pretrained(model_path,config=config,)\ninputs = tokenizer('grammar:i loving writing articles',padding='max_length', max_length=418, truncation=True, return_tensors=\"pt\").input_ids\nans_tokens = [-100 if x==0 else x for x in list(inputs[0])]\no=model.generate(torch.tensor(inputs))\ntokenizer.decode(o[0],skip_special_tokens=True, clean_up_tokenization_spaces=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:41:01.669884Z","iopub.status.idle":"2022-05-05T07:41:01.670417Z","shell.execute_reply.started":"2022-05-05T07:41:01.670175Z","shell.execute_reply":"2022-05-05T07:41:01.670198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}